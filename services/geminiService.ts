import { GoogleGenAI, Modality, Type, GenerateContentResponse, HarmBlockThreshold, HarmCategory } from "@google/genai";
import { 
    MockupConfig,
    ModificationRequest,
    GARMENT_CATEGORIES,
    DESIGN_STYLE_CATEGORIES,
    STYLE_OPTIONS,
    DesignLayer,
    FIT_OPTIONS,
    GARMENT_MATERIALS,
} from '../constants';
import { GeminiError } from './errors';


const API_KEY = process.env.API_KEY;

if (!API_KEY) {
  // This error is at initialization, so it doesn't need i18n
  throw new Error("API_KEY environment variable not set");
}

const ai = new GoogleGenAI({ apiKey: API_KEY });

export interface GroundingSource {
  uri: string;
  title: string;
}

// Helper to handle API errors for image generation
const handleImageGenerationError = (error: any, context: 'mockup' | 'graphic' | 'view' | 'render' | 'propagate' | 'modify' | 'filter', contextData?: any): GeminiError => {
    if (error instanceof GeminiError) {
        if (error.code === 'generation_blocked_safety' && context === 'graphic') {
            return new GeminiError('graphic_generation_safety', "Graphic generation blocked for safety.");
        }
        return error;
    }
    
    // Helper to robustly parse different error formats from the API
    const extractErrorDetails = (err: any): { message: string, status?: string } => {
        if (!err) return { message: 'Unknown error' };

        let potentialJson = '';
        if (typeof err === 'string') {
            potentialJson = err;
        } else if (typeof err.message === 'string') {
            potentialJson = err.message;
        } else {
            try {
                potentialJson = JSON.stringify(err);
            } catch {
                return { message: String(err) };
            }
        }

        try {
            const parsed = JSON.parse(potentialJson);
            const coreError = parsed.error || parsed;
            return {
                message: coreError.message || potentialJson,
                status: coreError.status,
            };
        } catch (e) {
            // Not a JSON string, just use it as the message
            return { message: potentialJson };
        }
    };

    const { message, status } = extractErrorDetails(error);
    const lowerMessage = message.toLowerCase();

    if (status === 'FAILED_PRECONDITION' || lowerMessage.includes('not available in your country')) {
        return new GeminiError('image_generation_unavailable', "Image generation is not available in your country. This is a regional restriction.");
    }
    if (lowerMessage.includes('model not found')) {
        return new GeminiError('model_not_found', "The selected AI model was not found. Please try another.");
    }
    
    const defaultMessages = {
        mockup: "Could not generate the mockup.",
        graphic: "No graphic was generated by the API.",
        view: `Could not generate the ${contextData} view.`,
        render: "Could not render the design.",
        propagate: `Could not propagate the design to the ${contextData} view.`,
        modify: "Could not modify the garment.",
        filter: `Could not apply the ${contextData} filter.`
    };
    const defaultCodes = {
        mockup: 'generic_mockup_generation_failed',
        graphic: 'no_graphic_from_api',
        view: 'additional_view_failed',
        render: 'render_generic_failed',
        propagate: 'propagate_generic_failed',
        modify: 'modify_generic_failed',
        filter: 'filter_generic_failed'
    };

    return new GeminiError(defaultCodes[context], defaultMessages[context]);
};


// Helper to convert data URL to base64 string
function dataUrlToBase64(dataUrl: string): string {
  const regex = /^data:image\/(png|jpeg|gif|webp);base64,/;
  return dataUrl.replace(regex, '');
}

// Helper to parse JSON from AI response
function cleanAndParseJson(jsonString: string): any {
  const match = jsonString.match(/\{[\s\S]*\}/);
  if (match && match[0]) {
    try {
      return JSON.parse(match[0]);
    } catch (error) {
      console.error("Failed to parse extracted JSON string:", match[0], error);
      throw new GeminiError("invalid_data_format", "The AI returned an invalid data format.");
    }
  }
  console.error("Could not find or parse JSON object in string:", jsonString);
  throw new GeminiError("invalid_data_format", "The AI returned an invalid data format.");
}

const getAIPersonaPrompt = (designStyle: string, garment: string, color: string): string => {
    const style = designStyle.toLowerCase();
    const base = `You are an expert fashion designer and AI prompt engineer specializing in creating apparel mockups. Your task is to act as a persona and generate a detailed, concise prompt for an image generation AI. Focus ONLY on the visual description of the garment itself. Do not mention models, backgrounds, or photorealism unless explicitly part of the garment's design (e.g., a photo print).`;

    let persona = "You are a modern, minimalist designer. You focus on clean lines, high-quality fabrics, and a neutral color palette.";
    if (style.includes('grunge')) {
        persona = "You are a vintage band t-shirt designer specializing in 'worn-in' and 'aged' looks. Think heavy flannel, faded graphics, and moody colors.";
    } else if (style.includes('y2k') || style.includes('2000s')) {
        persona = "You are a designer for a Y2K brand. Think bright colors, iridescent fabrics, 'bubble' fonts, rhinestones, and tight or cropped fits.";
    } else if (style.includes('gorpcore') || style.includes('outdoor')) {
        persona = "You are a designer for an outdoor techwear brand. You prioritize functionality, using technical fabrics like ripstop or Gore-Tex, with features like sealed seams and multiple pockets.";
    } else if (style.includes('streetwear')) {
        persona = "You are a lead designer for a high-end streetwear brand. You are an expert in oversized fits, premium materials like loopback cotton, and bold graphic placements.";
    }

    return `${base} Your current persona: ${persona} Based on this persona, generate a prompt for a ${color} ${garment}.`;
};

const getBaseGarmentDescription = (config: MockupConfig) => {
    return `${config.fit} ${config.selectedGarment} in ${config.selectedColor}, made of ${config.aiMaterialPrompt}`;
};

const handleApiResponse = (response: GenerateContentResponse): string => {
    if (response.promptFeedback?.blockReason) {
        const reason = response.promptFeedback.blockReason.toLowerCase();
        if (reason.includes('safety')) throw new GeminiError('generation_blocked_safety', "Generation blocked for safety.");
        if (reason.includes('recitation')) throw new GeminiError('generation_blocked_recitation', "Generation blocked for recitation.");
        throw new GeminiError('generation_failed_other', `Generation failed: ${response.promptFeedback.blockReason}`);
    }

    const firstCandidate = response.candidates?.[0];
    const firstPart = firstCandidate?.content.parts[0];

    if (firstPart && 'inlineData' in firstPart && firstPart.inlineData) {
        return `data:${firstPart.inlineData.mimeType};base64,${firstPart.inlineData.data}`;
    }

    throw new GeminiError('no_image_from_api', "No image was generated by the API.");
};


export const generateMockup = async (config: MockupConfig, view: string): Promise<{ imageUrl: string; groundingSources?: GroundingSource[] }> => {
    try {
        let finalPrompt = '';
        if (config.useAiApparel) {
            finalPrompt = config.aiApparelPrompt;
        } else {
            const personaPrompt = getAIPersonaPrompt(config.selectedDesignStyle, config.selectedGarment, config.selectedColor);
            const personaResponse = await ai.models.generateContent({
                model: 'gemini-2.5-flash',
                contents: personaPrompt
            });
            finalPrompt = personaResponse.text;
        }

        let finalPromptAdditions = '';

        if (config.selectedStyle === STYLE_OPTIONS.TECHNICAL_SKETCH) {
            finalPromptAdditions = `, technical flat sketch, single garment, clean lines, black and white, vector illustration style, ONLY the ${view} view, on a white background`;
        } else {
            if (config.useAiModelScene) {
                finalPromptAdditions = `, on a ${config.aiModelPrompt}, ${config.aiScenePrompt}, ${config.selectedStyle}, professional product photography, ONLY the ${view} view`;
            } else {
                let styleDescription = config.selectedStyle;
                if (styleDescription === STYLE_OPTIONS.PHOTOREALISTIC) {
                    styleDescription = STYLE_OPTIONS.GHOST_MANNEQUIN;
                }
                finalPromptAdditions = `, ${styleDescription}, professional product photography, isolated on a neutral gray background, no model, no person, no mannequin, studio lighting, ONLY the ${view} view`;
            }
        }
        
        finalPrompt += finalPromptAdditions;

        const contents = config.customMaterialTexture
            ? { parts: [{ text: finalPrompt }, { inlineData: { mimeType: 'image/png', data: dataUrlToBase64(config.customMaterialTexture) } }] }
            : finalPrompt;
        
        const response = await ai.models.generateContent({
            model: config.selectedModel,
            contents,
            config: {
                responseModalities: [Modality.IMAGE],
            },
        });
        const groundingMeta = response.candidates?.[0]?.groundingMetadata;
        const sources = groundingMeta?.groundingChunks
            ?.map(c => c.web ? { uri: c.web.uri, title: c.web.title } : null)
            .filter((s): s is GroundingSource => s !== null && s.uri !== '');

        return { imageUrl: handleApiResponse(response), groundingSources: sources };

    } catch (error) {
        console.error("Error generating mockup:", error);
        throw handleImageGenerationError(error, 'mockup');
    }
};

export const generateAdditionalView = async (baseImageUrl: string, config: MockupConfig, view: string): Promise<string> => {
     try {
        let prompt = `Based on the provided image of a ${getBaseGarmentDescription(config)}, generate a new photorealistic image of the EXACT same garment, but from the ${view} view. Maintain the exact same style, color, texture, and any existing graphics or designs.`;
        
        if (config.selectedStyle !== STYLE_OPTIONS.TECHNICAL_SKETCH) {
            if (!config.useAiModelScene) {
                prompt += ` Present the garment in a ghost mannequin style, isolated on a neutral gray background, with no model or person visible.`;
            }
        } else {
             prompt = `Based on the provided technical sketch of a ${getBaseGarmentDescription(config)}, generate a new technical flat sketch of the EXACT same garment, but from the ${view} view ONLY. Maintain the same clean, black and white vector style.`;
        }
        
        const response = await ai.models.generateContent({
            model: config.selectedModel,
            contents: { parts: [{ text: prompt }, { inlineData: { mimeType: 'image/png', data: dataUrlToBase64(baseImageUrl) } }] },
            config: { responseModalities: [Modality.IMAGE] },
        });
        return handleApiResponse(response);
    } catch (error) {
        console.error(`Error generating ${view} view:`, error);
        throw handleImageGenerationError(error, 'view', view);
    }
};

export const generateGraphic = async (prompt: string, garment: string, placement: string, color: string, designStyle: string, texturePrompt?: string, model: string = 'gemini-2.5-flash-image'): Promise<string> => {
    const fullPrompt = `Create a single, isolated graphic asset suitable for a ${garment} in a ${designStyle} style. The graphic should be: ${prompt}. The primary color should be ${color}. ${texturePrompt ? `The graphic should have a texture like ${texturePrompt}.`: ''} The graphic MUST have a transparent background. Do not include the garment itself in the image.`;
    try {
        const response = await ai.models.generateContent({
            model,
            contents: fullPrompt,
            config: { responseModalities: [Modality.IMAGE] }
        });
        return handleApiResponse(response);
    } catch (error) {
        console.error("Error generating graphic:", error);
        throw handleImageGenerationError(error, 'graphic');
    }
};

export const generateInspirationPrompt = async (garment: string, designStyle: string, color: string, mockupStyle: string): Promise<string> => {
    const prompt = `You are a creative director. Generate a single, concise, and inspiring prompt for an AI to create a graphic for a ${color} ${garment}. The style must be ${designStyle}. The mockup style is ${mockupStyle}. Provide only the prompt text itself, nothing else.`;
    try {
        const response = await ai.models.generateContent({ model: 'gemini-2.5-flash', contents: prompt });
        return response.text.trim();
    } catch (error) {
        console.error("Error getting inspiration:", error);
        throw new GeminiError('inspiration_failed', "The AI failed to generate an idea.");
    }
};

export const renderDesignOnMockup = async (baseImageUrl: string, layers: DesignLayer[], designStyle: string): Promise<string> => {
    if (!layers.some(l => l.visible)) throw new GeminiError('no_layers_for_render', "No visible layers to render.");
    try {
        const visibleLayers = layers.filter(l => l.visible);
        const prompt = `Apply the provided design layers onto the base garment image. Maintain the photorealism of the original mockup. The design style is ${designStyle}.`;

        const imageParts = [{ inlineData: { mimeType: 'image/png', data: dataUrlToBase64(baseImageUrl) } }];
        for (const layer of visibleLayers) {
            if (layer.type === 'image' || layer.type === 'drawing') {
                 imageParts.push({ inlineData: { mimeType: 'image/png', data: dataUrlToBase64(layer.content) } });
            }
        }

        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash-image',
            contents: { parts: [{ text: prompt }, ...imageParts] },
            config: { responseModalities: [Modality.IMAGE] }
        });
        return handleApiResponse(response);
    } catch (error) {
        console.error("Error rendering design:", error);
        throw handleImageGenerationError(error, 'render');
    }
};

export const propagateDesignToView = async (designedImageUrl: string, targetViewUrl: string, sourceView: string, targetView: string, designStyle: string): Promise<string> => {
    try {
        const prompt = `The first image shows a garment from the ${sourceView} view with a design applied. The second image shows the same garment from the ${targetView} view without the design. Accurately transfer the design from the first image to the second, wrapping it realistically around the garment for the ${targetView} view. The style is ${designStyle}.`;
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash-image',
            contents: { parts: [
                { text: prompt },
                { inlineData: { mimeType: 'image/png', data: dataUrlToBase64(designedImageUrl) } },
                { inlineData: { mimeType: 'image/png', data: dataUrlToBase64(targetViewUrl) } }
            ]},
            config: { responseModalities: [Modality.IMAGE] }
        });
        return handleApiResponse(response);
    } catch(error) {
        console.error(`Error propagating to ${targetView}:`, error);
        throw handleImageGenerationError(error, 'propagate', targetView);
    }
};

export const modifyGarmentImage = async (baseImageUrl: string, modification: ModificationRequest, designStyle: string): Promise<string> => {
    try {
        const prompt = `Perform a non-destructive edit on the provided garment image. The modification is of type "${modification.type}". Modification details: "${modification.content}". Apply it to the ${modification.location} area. The desired style for the modification is ${modification.style || designStyle}. Keep the rest of the image identical.`;
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash-image',
            contents: { parts: [{ text: prompt }, { inlineData: { mimeType: 'image/png', data: dataUrlToBase64(baseImageUrl) } }] },
            config: { responseModalities: [Modality.IMAGE] }
        });
        return handleApiResponse(response);
    } catch(error) {
        console.error("Error modifying garment:", error);
        throw handleImageGenerationError(error, 'modify');
    }
};

export const generateColorPalette = async (baseColor: string, designStyle: string): Promise<string[]> => {
    const prompt = `Generate a 5-color palette that complements a base color of ${baseColor} for a ${designStyle} apparel design. Return ONLY a JSON array of hex codes, like ["#FFFFFF", ...].`;
    try {
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents: prompt,
            config: { responseMimeType: 'application/json' }
        });
        const palette = JSON.parse(response.text);
        if (Array.isArray(palette) && palette.every(c => typeof c === 'string' && c.startsWith('#'))) {
            return palette;
        }
        throw new Error();
    } catch (error) {
        console.error("Error generating color palette:", error);
        throw new GeminiError('palette_generation_failed', "The AI failed to suggest a color palette.");
    }
};


export const applyGraphicFilter = async (baseImageUrl: string, filterType: 'vintage' | 'glitch' | 'distress'): Promise<string> => {
     try {
        let prompt = '';
        switch(filterType) {
            case 'vintage': prompt = 'Apply a convincing 90s vintage, faded, and slightly cracked effect to this graphic.'; break;
            case 'glitch': prompt = 'Apply a futuristic, cyberpunk-style glitch effect to this graphic.'; break;
            case 'distress': prompt = 'Apply a heavily distressed, grunge, worn-out effect to this graphic.'; break;
        }
        prompt += ' Maintain the original shape and colors as much as possible, and ensure the background remains transparent.';
        
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash-image',
            contents: { parts: [{ text: prompt }, { inlineData: { mimeType: 'image/png', data: dataUrlToBase64(baseImageUrl) } }] },
            config: { responseModalities: [Modality.IMAGE] }
        });
        return handleApiResponse(response);
    } catch (error) {
        console.error(`Error applying ${filterType} filter:`, error);
        throw handleImageGenerationError(error, 'filter', filterType);
    }
};


export const generateGarmentConcept = async (garment: string, styleA: string, styleB: string): Promise<string> => {
    const prompt = `You are a fashion concept artist. Create a detailed prompt for an AI image generator to visualize a garment. The garment is a ${garment}. It should be a creative fusion of two distinct styles: ${styleA} and ${styleB}. Describe the material, fit, key details, and overall aesthetic. Provide only the prompt text itself.`;
     try {
        const response = await ai.models.generateContent({ model: 'gemini-2.5-flash', contents: prompt });
        return response.text.trim();
    } catch (error) {
        console.error("Error generating concept:", error);
        throw new GeminiError('concept_failed', "The AI failed to generate a concept.");
    }
};

export const parseEasyPrompt = async (prompt: string): Promise<Partial<MockupConfig>> => {
    const allGarmentItems = GARMENT_CATEGORIES.flatMap(c => c.items);
    const allDesignStyles = DESIGN_STYLE_CATEGORIES.flatMap(c => c.items);
    
    const systemInstruction = `You are an intelligent assistant for an apparel mockup app. Your task is to parse a user's simple text prompt and map it to the available configuration options. Respond ONLY with a JSON object. The user prompt is: "${prompt}"`;
    
    try {
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents: prompt,
            config: {
                systemInstruction,
                responseMimeType: "application/json",
                responseSchema: {
                    type: Type.OBJECT,
                    properties: {
                        selectedGarment: { type: Type.STRING, description: "The single best matching garment type.", enum: allGarmentItems },
                        selectedDesignStyle: { type: Type.STRING, description: "The single best matching design style.", enum: allDesignStyles },
                        selectedColor: { type: Type.STRING, description: "The primary color mentioned, as a hex code." },
                        fit: { type: Type.STRING, description: "The best matching fit.", enum: FIT_OPTIONS },
                    },
                },
            }
        });

        const parsed = JSON.parse(response.text);

        // Find the category for the selected garment
        const garment = parsed.selectedGarment;
        const category = GARMENT_CATEGORIES.find(c => c.items.includes(garment));
        
        const result: Partial<MockupConfig> = {
            selectedGarment: garment,
            selectedCategory: category ? category.name : GARMENT_CATEGORIES[0].name,
            selectedDesignStyle: parsed.selectedDesignStyle,
            selectedColor: parsed.selectedColor,
            fit: parsed.fit,
        };

        const materials = GARMENT_MATERIALS[garment] || [];
        if (materials.length > 0) {
            result.aiMaterialPrompt = materials[0];
        }

        return result;

    } catch (error) {
        console.error("Error parsing easy prompt:", error);
        throw new GeminiError('parse_prompt_failed', "The AI could not understand the request.");
    }
};