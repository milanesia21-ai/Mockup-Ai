import { GoogleGenAI, Modality, Type, GenerateContentResponse, HarmBlockThreshold, HarmCategory } from "@google/genai";
import { 
    MockupConfig,
    ModificationRequest,
    GARMENT_CATEGORIES,
    DESIGN_STYLE_CATEGORIES,
    STYLE_OPTIONS,
    DesignLayer,
    FIT_OPTIONS,
    GARMENT_MATERIALS,
} from '../constants';
import { GeminiError } from './errors';


const API_KEY = process.env.API_KEY;

if (!API_KEY) {
  // This error is at initialization, so it doesn't need i18n
  throw new Error("API_KEY environment variable not set");
}

const ai = new GoogleGenAI({ apiKey: API_KEY });

export interface GroundingSource {
  uri: string;
  title: string;
}

export interface PrintArea {
  x: number; // top-left x, normalized (0-1)
  y: number; // top-left y, normalized (0-1)
  width: number;
  height: number;
}


// Helper to handle API errors for image generation
const handleImageGenerationError = (error: any, context: 'mockup' | 'graphic' | 'view' | 'render' | 'propagate' | 'modify' | 'filter', contextData?: any): GeminiError => {
    if (error instanceof GeminiError) {
        if (error.code === 'generation_blocked_safety' && context === 'graphic') {
            return new GeminiError('graphic_generation_safety', "Graphic generation blocked for safety.");
        }
        return error;
    }
    
    let messageToInspect = '';
    // Prioritize error.message if it exists, as it's often the most relevant part.
    if (error && typeof error.message === 'string') {
        messageToInspect = error.message;
    } else {
        // Fallback to stringifying the whole error object.
        try {
            messageToInspect = JSON.stringify(error);
        } catch {
            messageToInspect = String(error);
        }
    }

    // The message itself might be a JSON string. Try to parse it to get a deeper message.
    try {
        const parsed = JSON.parse(messageToInspect);
        if (parsed.error && typeof parsed.error.message === 'string') {
            messageToInspect = parsed.error.message;
        }
    } catch (e) {
        // Not a JSON string, or not the expected format. Proceed with the string as is.
    }

    const lowerCaseMessage = messageToInspect.toLowerCase();

    if (lowerCaseMessage.includes('failed_precondition') || lowerCaseMessage.includes('not available in your country')) {
        return new GeminiError('image_generation_unavailable', "Image generation is not available in your country. This is a regional restriction.");
    }
    if (lowerCaseMessage.includes('model not found')) {
        return new GeminiError('model_not_found', "The selected AI model was not found. Please try another.");
    }
     if (lowerCaseMessage.includes('unsupported_feature')) {
        return new GeminiError('unsupported_feature', "This feature is not supported for the selected model.");
    }
    
    const defaultMessages = {
        mockup: "Could not generate the mockup.",
        graphic: "No graphic was generated by the API.",
        view: `Could not generate the ${contextData} view.`,
        render: "Could not render the design.",
        propagate: `Could not propagate the design to the ${contextData} view.`,
        modify: "Could not modify the garment.",
        filter: `Could not apply the ${contextData} filter.`
    };
    const defaultCodes = {
        mockup: 'generic_mockup_generation_failed',
        graphic: 'no_graphic_from_api',
        view: 'additional_view_failed',
        render: 'render_generic_failed',
        propagate: 'propagate_generic_failed',
        modify: 'modify_generic_failed',
        filter: 'filter_generic_failed'
    };

    return new GeminiError(defaultCodes[context], defaultMessages[context]);
};


// Helper to convert data URL to base64 string
function dataUrlToBase64(dataUrl: string): string {
  const regex = /^data:image\/(png|jpeg|gif|webp);base64,/;
  return dataUrl.replace(regex, '');
}

// Helper to parse JSON from AI response
function cleanAndParseJson(jsonString: string): any {
  const match = jsonString.match(/\{[\s\S]*\}/);
  if (match && match[0]) {
    try {
      return JSON.parse(match[0]);
    } catch (error) {
      console.error("Failed to parse extracted JSON string:", match[0], error);
      throw new GeminiError("invalid_data_format", "The AI returned an invalid data format.");
    }
  }
  console.error("Could not find or parse JSON object in string:", jsonString);
  throw new GeminiError("invalid_data_format", "The AI returned an invalid data format.");
}

const getAIPersonaPrompt = (designStyle: string, garment: string, color: string): string => {
    const style = designStyle.toLowerCase();
    const base = `You are an expert fashion designer and AI prompt engineer specializing in creating apparel mockups. Your task is to act as a persona and generate a detailed, concise prompt for an image generation AI. Focus ONLY on the visual description of the garment itself. Do not mention models, backgrounds, or photorealism unless explicitly part of the garment's design (e.g., a photo print).`;

    let persona = "You are a modern, minimalist designer. You focus on clean lines, high-quality fabrics, and a neutral color palette.";
    if (style.includes('grunge')) {
        persona = "You are a vintage band t-shirt designer specializing in 'worn-in' and 'aged' looks. Think heavy flannel, faded graphics, and moody colors.";
    } else if (style.includes('y2k') || style.includes('2000s')) {
        persona = "You are a designer for a Y2K brand. Think bright colors, iridescent fabrics, 'bubble' fonts, rhinestones, and tight or cropped fits.";
    } else if (style.includes('gorpcore') || style.includes('outdoor')) {
        persona = "You are a designer for an outdoor techwear brand. You prioritize functionality, using technical fabrics like ripstop or Gore-Tex, with features like sealed seams and multiple pockets.";
    } else if (style.includes('streetwear')) {
        persona = "You are a lead designer for a high-end streetwear brand. You are an expert in oversized fits, premium materials like loopback cotton, and bold graphic placements.";
    }

    return `${base} Your current persona: ${persona} Based on this persona, generate a prompt for a ${color} ${garment}.`;
};

const getBaseGarmentDescription = (config: MockupConfig) => {
    return `${config.fit} ${config.selectedGarment} in ${config.selectedColor}, made of ${config.aiMaterialPrompt}`;
};

const handleApiResponse = (response: GenerateContentResponse): string => {
    // Check for prompt-level feedback which indicates a block before generation attempt
    if (response.promptFeedback?.blockReason) {
        const reason = response.promptFeedback.blockReason.toLowerCase();
        if (reason.includes('safety')) throw new GeminiError('generation_blocked_safety', "Generation blocked for safety.");
        if (reason.includes('recitation')) throw new GeminiError('generation_blocked_recitation', "Generation blocked for recitation.");
        throw new GeminiError('generation_failed_other', `Generation failed: ${response.promptFeedback.blockReason}`);
    }

    const firstCandidate = response.candidates?.[0];

    // Check if a candidate exists
    if (!firstCandidate) {
        throw new GeminiError('no_image_from_api', "No response candidate found from the API.");
    }
    
    // Check if the generation was blocked for any reason (e.g., safety)
    if (firstCandidate.finishReason && firstCandidate.finishReason !== 'STOP') {
        const reason = firstCandidate.finishReason.toLowerCase();
        if (reason.includes('safety')) {
            throw new GeminiError('generation_blocked_safety', "Generation blocked for safety.");
        }
        throw new GeminiError('no_image_from_api', `Generation failed with reason: ${firstCandidate.finishReason}`);
    }

    // Safely access the image data
    const firstPart = firstCandidate.content?.parts?.[0];

    if (firstPart && 'inlineData' in firstPart && firstPart.inlineData) {
        return `data:${firstPart.inlineData.mimeType};base64,${firstPart.inlineData.data}`;
    }

    // If we reach here, something is wrong with the response structure
    throw new GeminiError('no_image_from_api', "No valid image data was found in the API response.");
};


export const generateMockup = async (config: MockupConfig, view: string): Promise<{ imageUrl: string; groundingSources?: GroundingSource[] }> => {
    try {
        let finalPrompt = '';
        if (config.useAiApparel) {
            finalPrompt = config.aiApparelPrompt;
        } else {
            const personaPrompt = getAIPersonaPrompt(config.selectedDesignStyle, config.selectedGarment, config.selectedColor);
            const personaResponse = await ai.models.generateContent({
                model: 'gemini-2.5-flash',
                contents: personaPrompt
            });
            finalPrompt = personaResponse.text;
        }

        let finalPromptAdditions = '';

        if (config.selectedStyle === STYLE_OPTIONS.TECHNICAL_SKETCH) {
            finalPromptAdditions = `.
            **MANDATORY INSTRUCTIONS FOR TECHNICAL SKETCH:**
            1.  **Output Format:** Generate a technical flat sketch, also known as a flat drawing or fashion flat. This is a black and white vector-style illustration.
            2.  **Content:** The image MUST contain ONLY the line art for the garment's ${view} view.
            3.  **Background:** The background must be solid white.
            4.  **EXCLUSIONS: ABSOLUTELY DO NOT include any of the following:** text, numbers, measurements, annotations, sizing charts, spec sheets, tables, or any written information.
            5.  **Final Check:** The final image should be clean, professional, and ready for a design specification, containing only the garment drawing.`;
        } else {
            if (config.useAiModelScene) {
                finalPromptAdditions = `, on a ${config.aiModelPrompt}, ${config.aiScenePrompt}, ${config.selectedStyle}, professional product photography, ONLY the ${view} view`;
            } else {
                let styleDescription = config.selectedStyle;
                if (styleDescription === STYLE_OPTIONS.PHOTOREALISTIC) {
                    styleDescription = STYLE_OPTIONS.GHOST_MANNEQUIN;
                }
                finalPromptAdditions = `, ${styleDescription}, professional product photography, isolated on a neutral gray background, no model, no person, no mannequin, studio lighting, ONLY the ${view} view`;
            }
        }
        
        finalPrompt += finalPromptAdditions;

        if (config.selectedModel.startsWith('imagen')) {
            if (config.customMaterialTexture) {
                throw new GeminiError('unsupported_feature', "Imagen models do not support custom textures.");
            }
            const response = await ai.models.generateImages({
                model: config.selectedModel,
                prompt: finalPrompt,
                config: {
                    numberOfImages: 1,
                    outputMimeType: 'image/png',
                },
            });
            
            if (!response.generatedImages || response.generatedImages.length === 0) {
                 throw new GeminiError('no_image_from_api', "No image was generated by the API.");
            }

            const base64ImageBytes: string = response.generatedImages[0].image.imageBytes;
            const imageUrl = `data:image/png;base64,${base64ImageBytes}`;
            return { imageUrl, groundingSources: undefined };
        } else {
            const contents = config.customMaterialTexture
                ? { parts: [{ text: finalPrompt }, { inlineData: { mimeType: 'image/png', data: dataUrlToBase64(config.customMaterialTexture) } }] }
                : finalPrompt;
            
            const response = await ai.models.generateContent({
                model: config.selectedModel,
                contents,
                config: {
                    responseModalities: [Modality.IMAGE],
                },
            });
            const groundingMeta = response.candidates?.[0]?.groundingMetadata;
            const sources = groundingMeta?.groundingChunks
                ?.map(c => c.web ? { uri: c.web.uri, title: c.web.title } : null)
                .filter((s): s is GroundingSource => s !== null && s.uri !== '');

            return { imageUrl: handleApiResponse(response), groundingSources: sources };
        }

    } catch (error) {
        console.error("Error generating mockup:", error);
        throw handleImageGenerationError(error, 'mockup');
    }
};

export const generateAdditionalView = async (baseImageUrl: string, config: MockupConfig, view: string): Promise<string> => {
     try {
        let prompt = `Based on the provided image of a ${getBaseGarmentDescription(config)}, generate a new photorealistic image of the EXACT same garment, but from the ${view} view. Maintain the exact same style, color, texture, and any existing graphics or designs.`;
        
        if (config.selectedStyle !== STYLE_OPTIONS.TECHNICAL_SKETCH) {
            if (!config.useAiModelScene) {
                prompt += ` Present the garment in a ghost mannequin style, isolated on a neutral gray background, with no model or person visible.`;
            }
        } else {
             prompt = `From the provided image of a ${getBaseGarmentDescription(config)}, create a technical flat sketch of the ${view} view.
            **MANDATORY INSTRUCTIONS:**
            1.  **Style:** Match the clean, black-and-white, vector line art style of a professional fashion flat.
            2.  **Content:** The image MUST ONLY contain the line drawing of the garment.
            3.  **EXCLUSIONS: DO NOT include any text, numbers, measurements, annotations, or callouts.** The final image must be pure line art on a white background.`;
        }
        
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash-image', // Use a model that supports image-to-image tasks
            contents: { parts: [{ text: prompt }, { inlineData: { mimeType: 'image/png', data: dataUrlToBase64(baseImageUrl) } }] },
            config: { responseModalities: [Modality.IMAGE] },
        });
        return handleApiResponse(response);
    } catch (error) {
        console.error(`Error generating ${view} view:`, error);
        throw handleImageGenerationError(error, 'view', view);
    }
};

export const generateGraphic = async (prompt: string, garment: string, placement: string, color: string, designStyle: string, texturePrompt?: string, model: string = 'gemini-2.5-flash-image'): Promise<string> => {
    const fullPrompt = `Create a single, isolated graphic asset suitable for a ${garment} in a ${designStyle} style. The graphic should be: ${prompt}. The primary color should be ${color}. ${texturePrompt ? `The graphic should have a texture like ${texturePrompt}.`: ''} The graphic MUST have a transparent background. Do not include the garment itself in the image.`;
    try {
        if (model.startsWith('imagen')) {
             const response = await ai.models.generateImages({
                model,
                prompt: fullPrompt,
                config: {
                    numberOfImages: 1,
                    outputMimeType: 'image/png',
                },
            });
            if (!response.generatedImages || response.generatedImages.length === 0) {
                 throw new GeminiError('no_image_from_api', "No image was generated by the API.");
            }
            const base64ImageBytes: string = response.generatedImages[0].image.imageBytes;
            return `data:image/png;base64,${base64ImageBytes}`;
        } else {
            const response = await ai.models.generateContent({
                model,
                contents: fullPrompt,
                config: { responseModalities: [Modality.IMAGE] }
            });
            return handleApiResponse(response);
        }
    } catch (error) {
        console.error("Error generating graphic:", error);
        throw handleImageGenerationError(error, 'graphic');
    }
};

export const generateInspirationPrompt = async (garment: string, designStyle: string, color: string, mockupStyle: string): Promise<string> => {
    const prompt = `You are a creative director. Generate a single, concise, and inspiring prompt for an AI to create a graphic for a ${color} ${garment}. The style must be ${designStyle}. The mockup style is ${mockupStyle}. Provide only the prompt text itself, nothing else.`;
    try {
        const response = await ai.models.generateContent({ model: 'gemini-2.5-flash', contents: prompt });
        return response.text.trim();
    } catch (error) {
        console.error("Error getting inspiration:", error);
        throw new GeminiError('inspiration_failed', "The AI failed to generate an idea.");
    }
};

export const renderDesignOnMockup = async (baseImageUrl: string, layers: DesignLayer[], designStyle: string): Promise<string> => {
    if (!layers.some(l => l.visible)) throw new GeminiError('no_layers_for_render', "No visible layers to render.");
    try {
        const visibleLayers = layers.filter(l => l.visible);
        const prompt = `Apply the provided design layers onto the base garment image. Maintain the photorealism of the original mockup. The design style is ${designStyle}.`;

        const imageParts = [{ inlineData: { mimeType: 'image/png', data: dataUrlToBase64(baseImageUrl) } }];
        for (const layer of visibleLayers) {
            if (layer.type === 'image' || layer.type === 'drawing') {
                 imageParts.push({ inlineData: { mimeType: 'image/png', data: dataUrlToBase64(layer.content) } });
            }
        }

        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash-image',
            contents: { parts: [{ text: prompt }, ...imageParts] },
            config: { responseModalities: [Modality.IMAGE] }
        });
        return handleApiResponse(response);
    } catch (error) {
        console.error("Error rendering design:", error);
        throw handleImageGenerationError(error, 'render');
    }
};

export const propagateDesignToView = async (designedImageUrl: string, targetViewUrl: string, sourceView: string, targetView: string, designStyle: string): Promise<string> => {
    try {
        const prompt = `The first image shows a garment from the ${sourceView} view with a design applied. The second image shows the same garment from the ${targetView} view without the design. Accurately transfer the design from the first image to the second, wrapping it realistically around the garment for the ${targetView} view. The style is ${designStyle}.`;
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash-image',
            contents: { parts: [
                { text: prompt },
                { inlineData: { mimeType: 'image/png', data: dataUrlToBase64(designedImageUrl) } },
                { inlineData: { mimeType: 'image/png', data: dataUrlToBase64(targetViewUrl) } }
            ]},
            config: { responseModalities: [Modality.IMAGE] }
        });
        return handleApiResponse(response);
    } catch(error) {
        console.error(`Error propagating to ${targetView}:`, error);
        throw handleImageGenerationError(error, 'propagate', targetView);
    }
};

export const modifyGarmentImage = async (baseImageUrl: string, modification: ModificationRequest, designStyle: string): Promise<string> => {
    try {
        const prompt = `Perform a non-destructive edit on the provided garment image. The modification is of type "${modification.type}". Modification details: "${modification.content}". Apply it to the ${modification.location} area. The desired style for the modification is ${modification.style || designStyle}. Keep the rest of the image identical.`;
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash-image',
            contents: { parts: [{ text: prompt }, { inlineData: { mimeType: 'image/png', data: dataUrlToBase64(baseImageUrl) } }] },
            config: { responseModalities: [Modality.IMAGE] }
        });
        return handleApiResponse(response);
    } catch(error) {
        console.error("Error modifying garment:", error);
        throw handleImageGenerationError(error, 'modify');
    }
};

export const generateColorPalette = async (baseColor: string, designStyle: string): Promise<string[]> => {
    const prompt = `Generate a 5-color palette that complements a base color of ${baseColor} for a ${designStyle} apparel design. Return ONLY a JSON array of hex codes, like ["#FFFFFF", ...].`;
    try {
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents: prompt,
            config: { responseMimeType: 'application/json' }
        });
        const palette = JSON.parse(response.text);
        if (Array.isArray(palette) && palette.every(c => typeof c === 'string' && c.startsWith('#'))) {
            return palette;
        }
        throw new Error();
    } catch (error) {
        console.error("Error generating color palette:", error);
        throw new GeminiError('palette_generation_failed', "The AI failed to suggest a color palette.");
    }
};


export const applyGraphicFilter = async (baseImageUrl: string, filterType: 'vintage' | 'glitch' | 'distress'): Promise<string> => {
     try {
        let prompt = '';
        switch(filterType) {
            case 'vintage': prompt = 'Apply a convincing 90s vintage, faded, and slightly cracked effect to this graphic.'; break;
            case 'glitch': prompt = 'Apply a futuristic, cyberpunk-style glitch effect to this graphic.'; break;
            case 'distress': prompt = 'Apply a heavily distressed, grunge, worn-out effect to this graphic.'; break;
        }
        prompt += ' Maintain the original shape and colors as much as possible, and ensure the background remains transparent.';
        
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash-image',
            contents: { parts: [{ text: prompt }, { inlineData: { mimeType: 'image/png', data: dataUrlToBase64(baseImageUrl) } }] },
            config: { responseModalities: [Modality.IMAGE] }
        });
        return handleApiResponse(response);
    } catch (error) {
        console.error(`Error applying ${filterType} filter:`, error);
        throw handleImageGenerationError(error, 'filter', filterType);
    }
};


export const generateGarmentConcept = async (garment: string, styleA: string, styleB: string): Promise<string> => {
    const prompt = `You are a fashion concept artist. Create a detailed prompt for an AI image generator to visualize a garment. The garment is a ${garment}. It should be a creative fusion of two distinct styles: ${styleA} and ${styleB}. Describe the material, fit, key details, and overall aesthetic. Provide only the prompt text itself.`;
     try {
        const response = await ai.models.generateContent({ model: 'gemini-2.5-flash', contents: prompt });
        return response.text.trim();
    } catch (error) {
        console.error("Error generating concept:", error);
        throw new GeminiError('concept_failed', "The AI failed to generate a concept.");
    }
};

export const parseEasyPrompt = async (prompt: string): Promise<Partial<MockupConfig>> => {
    const allGarmentItems = GARMENT_CATEGORIES.flatMap(c => c.items);
    const allDesignStyles = DESIGN_STYLE_CATEGORIES.flatMap(c => c.items);
    
    const systemInstruction = `You are an intelligent assistant for an apparel mockup app. Your task is to parse a user's simple text prompt and map it to the available configuration options. Respond ONLY with a JSON object. The user prompt is: "${prompt}"`;
    
    try {
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents: prompt,
            config: {
                systemInstruction,
                responseMimeType: "application/json",
                responseSchema: {
                    type: Type.OBJECT,
                    properties: {
                        selectedGarment: { type: Type.STRING, description: "The single best matching garment type.", enum: allGarmentItems },
                        selectedDesignStyle: { type: Type.STRING, description: "The single best matching design style.", enum: allDesignStyles },
                        selectedColor: { type: Type.STRING, description: "The primary color mentioned, as a hex code." },
                        fit: { type: Type.STRING, description: "The best matching fit.", enum: FIT_OPTIONS },
                    },
                },
            }
        });

        const parsed = JSON.parse(response.text);

        // Find the category for the selected garment
        const garment = parsed.selectedGarment;
        const category = GARMENT_CATEGORIES.find(c => c.items.includes(garment));
        
        const result: Partial<MockupConfig> = {
            selectedGarment: garment,
            selectedCategory: category ? category.name : GARMENT_CATEGORIES[0].name,
            selectedDesignStyle: parsed.selectedDesignStyle,
            selectedColor: parsed.selectedColor,
            fit: parsed.fit,
        };

        const materials = GARMENT_MATERIALS[garment] || [];
        if (materials.length > 0) {
            result.aiMaterialPrompt = materials[0];
        }

        return result;

    } catch (error) {
        console.error("Error parsing easy prompt:", error);
        throw new GeminiError('parse_prompt_failed', "The AI could not understand the request.");
    }
};

export const analyzePrintArea = async (imageUrl: string): Promise<PrintArea> => {
    const prompt = `Analyze this image of a garment. Identify the primary printable area (e.g., the center chest on a t-shirt, the main front panel of a hoodie). Return ONLY a JSON object with the coordinates of this area. The coordinates must be normalized from 0 to 1. The JSON object should have keys "x", "y", "width", and "height", where (x,y) is the top-left corner of the bounding box.`;
    
    try {
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents: { parts: [
                { text: prompt },
                { inlineData: { mimeType: 'image/png', data: dataUrlToBase64(imageUrl) } }
            ]},
            config: {
                responseMimeType: "application/json",
                responseSchema: {
                    type: Type.OBJECT,
                    properties: {
                        x: { type: Type.NUMBER, description: "Normalized top-left x-coordinate (0-1)." },
                        y: { type: Type.NUMBER, description: "Normalized top-left y-coordinate (0-1)." },
                        width: { type: Type.NUMBER, description: "Normalized width (0-1)." },
                        height: { type: Type.NUMBER, description: "Normalized height (0-1)." },
                    },
                    required: ["x", "y", "width", "height"],
                },
            }
        });

        const parsed: PrintArea = JSON.parse(response.text);
        
        // Basic validation
        if (
            typeof parsed.x !== 'number' ||
            typeof parsed.y !== 'number' ||
            typeof parsed.width !== 'number' ||
            typeof parsed.height !== 'number' ||
            parsed.x < 0 || parsed.y < 0 || parsed.width <= 0 || parsed.height <= 0 ||
            (parsed.x + parsed.width) > 1.1 || (parsed.y + parsed.height) > 1.1 // Allow slight overage
        ) {
            throw new Error("Invalid coordinates received from AI.");
        }
        
        return parsed;

    } catch (error) {
        console.error("Error analyzing print area:", error);
        throw new GeminiError('print_area_analysis_failed', "The AI could not analyze the garment's print area.");
    }
};